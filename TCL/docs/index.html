<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
  body {
    font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    width: 1100px;
  }

  h1 {
    font-weight:300;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  .link2 {
    text-decoration: none;
    display: inline;
    margin-right: 5px;
  }

  .fakelink {
    text-decoration: none;
    /* cursor: pointer; */
  }

  element.style {
    overflow: hidden;
    display: block;
  }
  .pre-white-space {
    white-space: pre;
  }
  .bibref {
    margin-top: 10px;
    margin-left: 10px;
    display: none;
    font-size: 14px;
    font-family: monospace;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>
<script type="text/javascript" src="resources/hidebib.js"></script>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <head>
    <link rel="icon" type="image/png" href="resources/ucsd_logo.png">
    <title>Semi-Supervised Action Recognition with Temporal Contrastive Learning</title>
    <meta property='og:title' content='Semi-Supervised Action Recognition with Temporal Contrastive Learning' />
    <meta property="og:description" content="Singh, Chakraborty, Varshney, Panda, Feris, Saenko, Das. Semi-Supervised Action Recognition with Temporal Contrastive Learning. In CVPR, 2021." />
    <meta property='og:url' content='https://cvir.github.io/TCL/' />
  </head>
  <body>
        <br>
        <center><span style="font-size:40px;font-weight:bold;color:#182B49">Semi-Supervised Action Recognition with  <br/> Temporal Contrastive Learning</span></center>

        <table align=center width=900px>
          <tr>
            <td align=center width=180px>
            <center><span style="font-size:20px"><a href="https://griffintaur.github.io/" target="_blank">Ankit
            Singh</a><sup>1</sup></span></center></td>
            <td align=center width=180px>
              <center><span style="font-size:20px"><a href="https://scholar.google.co.in/citations?user=Z0uiqiIAAAAJ&hl=en" target="_blank"> Omprakash Chakraborty</a><sup>2</sup></span></center></td>
            <td align=center width=180px>
                <center><span style="font-size:20px"><a href="http://cse.iitkgp.ac.in/~ashutoshv/" target="_blank"> Ashutosh Varshney</a><sup>2</sup></span></center></td>
            <td align=center width=180px>
                <center><span style="font-size:20px"><a href="https://rpand002.github.io/" target="_blank">Rameswar Panda</a><sup>3</sup></span></center></td>
            <tr/>
         </table>

         <table align=center width=600px>
            <tr>
              <td align=center width=150px>
                <center><span style="font-size:20px"><a href="http://rogerioferis.com/" target="_blank">Rogerio Feris</a><sup>3</sup></span></center></td>
          <td align=center width=150px>
            <center><span style="font-size:20px"><a href="http://ai.bu.edu/ksaenko.html" target="_blank">Kate Saenko</a><sup>3,</sup><sup>4</sup></span></center></td>
        <td align=center width=150px>
            <center><span style="font-size:20px"><a href="https://cse.iitkgp.ac.in/~adas/" target="_blank">Abir Das</a><sup>2</sup></span></center></td>
        <tr/>
      </table>

        <table align=center width=800px>
          <tr>
            <td align=center width=150px><center><sup>1 </sup><span style="font-size:18px">IIT Madras</span></center></td>
            <td align=center width=150px><center><sup>2 </sup><span style="font-size:18px">IIT Kharagpur</span></center></td>
            <td align=center width=150px><center><sup>3 </sup><span style="font-size:18px">MIT-IBM Watson AI Lab</span></center></td>
            <td align=center width=150px><center><sup>4 </sup><span style="font-size:18px">Boston University</span></center></td>
          <tr/>
        </table> 
        <table align=center width=400px>
          <tr>
            <td align=center width=150px>
            <center><span style="font-size:24px"><a href="http://cvpr2021.thecvf.com/" target="_blank">CVPR 2021</a></span></center></td>
          <tr/>
        </table>
        <table align=center width=900px>
            <tr><td width=900px>
              <center><a href="resources/arch.png"><img src = "resources/arch.png"></img></a><br></center>
            </td></tr>
        </table>

        <center id="abstract"><h1>Abstract</h1></center>
        Learning to recognize actions from only a handful of labeled videos is a challenging problem due to the scarcity of tediously collected activity labels.  We approach this problem by learning a two-pathway temporal contrastive model using unlabeled videos at two different speeds leveraging the fact that changing video speed does not change an action.   Specifically,  we  propose  to  maximize  the  similarity between encoded representations of the same video at two different speeds as well as minimize the similarity between different videos played at different speeds. This way we use the rich supervisory information in terms of ‘time’ that is present in otherwise unsupervised pool of videos. With this simple yet effective strategy of manipulating video playbackrates, we considerably outperform video extensions of sophisticated state-of-the-art semi-supervised image recognition  methods  across  multiple  diverse  benchmark  datasets and network architectures.  Interestingly, our proposed approach benefits from out-of-domain unlabeled videos showing generalization and robustness.  We also perform rigorous ablations and analysis to validate our approach <br>
        <br>
        <hr>

        <center id="results0"><h1>Comparative Study of TCL </h1></center>
        <table align=center width=500px>
            <tr><td width=500px>
              <center><a href="resources/comp.png"><img src = "resources/comp.png" height="320px"></img></a><br></center>
            </td></tr>
          </table>
          <caption width=500px align="center">Comparison of top-1 accuracy for <strong>TCL</strong>(Ours) with Pseudo-Label and FixMatch baselines trained with different percentages of labeled training data</caption>
        <br>
        <br>
        <br>
        <hr>

        <center id="results0"><h1>Results on Mini-Something-V2</h1></center>
        <table align=center width=1000px>
            <tr><td width=500px>
              <center><a href="resources/table.png"><img src = "resources/Mini-Something_results.png" height="320px"></img></a><br></center>
            </td></tr>
          </table>
        <br>
        <hr>


        
        <center id="sourceCode"><h1>Paper, code and other details</h1></center>


        <table align=center width=900px>
            <tr></tr>
          <tr>
            <td >
        <a href="https://cvir.github.io/TCL/"><img class="paperpreview" src="resources/arch_small.png" width="200px"/></a>
          </td>
          <td></td>
          <td width=700px > <span style="font-size:20px">
            Ankit Singh*, Omprakash Chakraborty*, Ashutosh Varshney, Rameswar Panda, Rogerio Feris, Kate Saenko, Abir Das<br/> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Singh_Semi-Supervised_Action_Recognition_With_Temporal_Contrastive_Learning_CVPR_2021_paper.pdf">Semi-Supervised Action Recognition with Temporal Contrastive Learning</a> <br/> <i>Computer Vision and Pattern Recognition (CVPR)</i>, 2021 <br/>
            [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Singh_Semi-Supervised_Action_Recognition_With_Temporal_Contrastive_Learning_CVPR_2021_paper.pdf">PDF</a>]
            [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Singh_Semi-Supervised_Action_Recognition_CVPR_2021_supplemental.pdf">Supp</a>]
            
            [<a href="https://github.com/CVIR/TCL">Code</a>]
            [<a href="resources/TCL_bib.txt">Bibtex</a>]
[<a href="https://www.youtube.com/watch?v=_qIYu3EU2kY">Video Presentation</a>]
[<a href="resources/Semi-Supervised Action Recognition With Temporal Contrastive Learning.pdf">Poster</a>]

</span>
        </td>
        </tr>

      </table>

      <br>
      <hr>

      <br/>

    <br><br>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
</body>
</html>
